"""
### GridSearchCV

- 모델의 일반화 성능을 개선하기 위한 매개변수 튜닝 (파라미터를 a로도 해보고 b로도 해봐서 최적의 것을 알려줘) 
- GridSearchCV(estimator, param_grid)
    - 조정하고자 하는 매개변수명과 설정값에 대해서 딕셔너리 타입으로 전달
    - 기본값으로 3-fold cross-validation을 적용 (교차 검증을 하여 평균 사용) 
    - 분석모델로 분류기가 전달되면 stratified 3-fold cross-validation 적용
    - 일반적인 분석 모델 객체와 유사하게 GridSearch 객체도 predict, score 메서드 제공
        - predict() : 찾아낸 최적의 매개변수로 학습된 모델로부터 예측값 얻기 (제일 좋은 값으로 얻어줌)
        - score() : 찾아낸 최적의 매개변수로로 학습된 모델의 일반화 성능 평가
    - 최적의 매개변수를 찾는 과정에서는 학습 데이터만 사용할 뿐 테스트 데이터는 사용하지 않음
        - grid_scores_
            - 모든 하이퍼파리미터 조합에 대한 성능 결과
            - parameters: 사용된 파라미터
            - mean_validation_score: 교차 검증(cross-validation) 결과의 평균값
            - cv_validation_scores: 모든 교차 검증(cross-validation) 결과
        - best_params_ : 찾아낸 최적의 매개변수
        - best_score_ : 최적의 매개변수로 학습 데이터에서 얻은 최상의 교차 검증 정확도
        - best_estimator_ : 최적의 매개변수에서 학습 데이터를 사용해서 학습한 모델 객체
 """
 
# k-nn
# 이웃점개수 [1,3,5,7,9]
# 거리계산 [유클리디안,민코스크]
# 5 * 2 = 10개의 케이스 계산 조합갯수가 많아지면 처리하기 어려워진다. 

#IRIS 데이터셋 사용
from sklearn import datasets

iris = datasets.load_iris()

# 독립변수(문제), 종속변수(정답) 분리

iris_x = iris.data
iris_y = iris.target

#학습, 평가 데이터 분리 (7:3)
from sklearn.model_selection import train_test_split

train_x, test_x, train_y, test_y = train_test_split(iris_x, iris_y, test_size=.3)

train_x.shape

test_x.shape

# RandomForest 모델 객체 생성
from sklearn.ensemble import RandomForestClassifier

rf = RandomForestClassifier()

#그리드서치 라이브러리
from sklearn.model_selection import GridSearchCV


# GridSearchCV(model 변수, 파라미터조합(딕셔너리))
# 그리드서치를 수행할 파라미터의 경우의 수를 딕셔너리로 생성(하이퍼파라미터 맵)
# n_estimator: 분류기 생성 횟수
# max_features : 독립변수의 최대 개수
# max_depth : 의사결정나무의 최대 깊이
# criterion : 불순도 지표
param_map = {'n_estimators' : [50,100,150,200,250,300],
            'max_depth':[1,3,5,7,9,10]}

# 파라미터를 일일이 바꿔 모델을 튜닝하는것이 번거로우니 자동으로 하는 것.
# 현재 param_map은 36번 명령을 해야한다. => 한번에 끝 
param_map

# 하이퍼파라미터맵과 모델 겹합
grid_search = GridSearchCV(estimator = rf, param_grid=param_map)
# 첫번째 파라미터에 어떤 알고리즘을 쓸 것인지 넣어준다.
# 두번째 파라미터는 파라미터 조합은 어떻게 한다. 

# 결합된 변수에 .fit() 명령어 사용
grid_search.fit(train_x,train_y)

#학습결과를 기반으로 최고의 성능을 가지는 하이퍼파라미터 조합 반환 
grid_search.best_params_

# 최고의 성능을 가지는 하이퍼파라미터 조합 사용시의 전체 파라미터 현황 반환 
grid_search.best_estimator_

# 최고 조합일때의 성능
grid_search.best_score_

# best_params_의 조합을 이용해 예측하기 (.score())
grid_search.score(test_x,test_y)

