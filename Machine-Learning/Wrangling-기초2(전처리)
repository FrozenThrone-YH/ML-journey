#라이브러리 임포트
import pandas as pd
import numpy as np

"""
#### 데이터 값에 대한 처리
- 결측값 (항목은 있으나 값이 없음 => 0으로 처리하거나 평균으로 처리하거나)
- 이상치 (값이 한계치까지만 표기, 얼토당토않은 수치)
- 단순 중복 데이터
- 동일한 의미, 다른 명칭의 중복 데이터
- ★중복속성(다중공선성) 
   => 다른 자료로 간주되는 것끼리 corr값이 1에 가깝게 나오면 거의 같은 자료인지 의심을
   => 소거해주는 경우가 많다. 
- 불규칙한 데이터 수집(간격, 단위)"""

# 데이터 적재
sample = pd.read_csv('data/csv_exam_nan.csv')
sample

"""
#### 결측치 처리 - 삭제
- 결측치가 하나라도 있는 레코드 삭제 
- 모든 값이 결측인 레코드 삭제 
- 결측치가 하나라도 있는 데이터만 선택"""

#결측치가 하나라도 있는 레코드 삭제
#df.dropna(how='any'(default),inplace=True)
#inplace=True : 원본에 바로 적용
sample.dropna()
sample

#모든 값이 결측인 레코드(row)만 삭제
# df.dropna(how='all')
sample.dropna(how='all')

#결측치가 하나라도 있는 데이터만 선택
#조건색인
# df[df,isnull().any(axis=1)]
sample[sample.isnull().any(axis=1)]

# 결과값 기준으로 컬럼에 대해 결측치 여부 bool type 반환
sample.isnull().any() #axis=0(default)

sample.isnull().any(axis=1)

#컬럼별 결측치의 개수
sample.isnull().sum()

"""
### 결측치 처리 - 대체 값
- 연속형 : 임의값(0), mean, median, 예측값(머신러닝 이용), 도메인지식 활용
- 명목형 : mode(최빈값), 예측값(남자인지 여자인지 예측해라), 도메인지식 활용

ex) 삼수 하면 내신 점수가 사라지는데, 정시에서 내신 점수를 보면 수능값을 내신값으로 대체하는 경우 """

# 연속형 - 임의의 값 대체
# df.fillna(value)
sample.fillna(0)

# mean - 1) 전체 데이터의 평균값
# sample : 6 x 3의 모든 데이터에 대한 평균
# df.mean() : 컬럼별로 평균값

sample.mean() # NaN을 제외한 나머지 데이터에 대한 평균

# 전체 평균 결측치에 대입하기 
# df.values.mean() : array 타입의 연산으로 NaN 값이 하나라도 있으면
# 최종 결과는 NaN
# sample.values.mean() -> NaN
# df.fallna(0) -> mean()

tot_avg=sample.fillna(0).values.mean()
sample.fillna(tot_avg)

tot_avg=sample.fillna(0).values.mean()
tot_avg

# mean - 2) 결측치가 존재하는 속성(변수 = 컬럼)의 평균값 
# sample : math/en/sc 컬럼에 존재하는 결측치 -> math/en/sc 컬럼의 평균값 
# df.mean() : 컬럼별 평균
sample.mean()

print(sample.mean()[0]) # math
print(sample.mean()[1]) # englisg
print(sample.mean()[2]) # science

# 전체데이터가 아닌 컬럼별로 맞는 값을 .fillna()해줌
# math 컬럼에만 값을 집어 넣는 경우는 sample['math'].fillna(값)을 이용한다.
# sample['math'].fillna(sample['math'].mean()) 
sample['math'].fillna(sample.mean()[0])

sample['english'].fillna(sample.mean()[1])

sample['science'].fillna(sample.mean()[2])

# median - 전체 데이터에 대한 중위값
# tot_avg : 54.5
# median : 86
tot_med=pd.Series(sample.values.reshape(18)).median()
tot_med

#sampel에 대해서 전체 데이터를 중위값으로 NaN채우기 
sample.fillna(tot_med) # NaN를 제외한 값들의 중위수가 86이라서 높게 나온다. 

#속성별 중위값 (인덱스 이용)
print(sample.median()[0])
print(sample.median()[1])
print(sample.median()[2])

# 전체 데이터가 아닌 컬럼별로 맞는 값(중위값)을 .fillna() 해주세요 
#math 칼럼
sample['math'].fillna(sample.median()[0])

#english 칼럼
sample['english'].fillna(sample.median()[1])

#science 칼럼
sample['science'].fillna(sample.median()[2])

# mode - 범주형 (문자열 등) 데이터에서는 최빈값을 사용
# describe()
# value_counts()
# collections 라이브러리의 Counter 모듈

df=pd.DataFrame({'label':['A','B','B','C','C','C','D']})
df
df.describe()
df.describe().loc['top']

# 특정 요소의 출현 횟수를 딕셔너리로 정리하기
# 2. 명목형 - mode(최빈값)
# 리스트, 튜플타입

from collections import Counter

# 1. 라이브러리 가져오기
# 2. Counter() 객체 생성
# 3. Counter객체.most_common() => [(value1, 갯수),(value2,갯수),...]

colors=['red','blue','pink','blue','blue','red']
counter=Counter(colors)
counter

# most_common() => 특정 요소와 그 요소의 출현 횟수를 빈출순으로 나열
counter.most_common()

#최빈값을 반환하는 사용자 정의함수 1 
# 인자값으로 리스트를 넘기면 최빈값 범주를 반환
# 함수명, 매개변수(리스트) 정의
# 함수 실행문
# 1) 리스트에 대해서 Counter() 함수 적용
# 2) 1번 결과에 대해서 most_common() 함수 적용
# 3) 2번 결과에 대해서 0번째 아이템의 0번째 요소 (value, count)
# 4) 3번 결과를 반환 / print() vs return

def mode_finder(x):
    result = Counter(x)
    mode = result.most_common()[0][0]
    return mode

# 리스트를 만들어서 빈출요소만 조회되는지 확인해주세요
mode_finder(['a','a','b','b','b','c'])

mode_finder(['a','a','b','b','b','c','c','c']) #동점인 경우 순번이 앞선 것 먼저 나온다. 

# 동일 최빈값이 2개 이상인 경우
# for 반복문 & if문
# 동일 최빈값 확인 : 최빈값 아이템의 value 를 찾아서 비교
# 최종결과 : 리스트에 동일 최빈값인 범주를 담기 

def mode_finder2(x):
    c = Counter(x)
    result = c.most_common()
    most_value=result[0][1] # value가 아닌 횟수를 먼저 저장
    modes=[]
    
    for i in result:
        if i[1] == most_value:
            modes.append(i[0])
    return modes
    
 mode_finder2(['a','a','b','b','b','c','c','c'])
 
 # 데이터 프레임
df = pd.DataFrame({'label':['a','a','a','b','b','b','c','c','c','d']})
df

# COunter와 .most_common()을 이용해서 빈출횟수를 순서대로 나열해보세요 
Counter(df['label']).most_common()

"""
### 데이터 단위 통일

#### 표준화(Standardization)
- 평균을 기준으로 얼마나 떨어져 있는지를 파악
- sklearn에서 제공하는 전처리 클래스
    - preprocessing 클래스
        - scaler() : 전체 자료의 분포를 평균 0, 표준편차 1이 되도록 스케일링
        - minmax_scale() : 최대/최소값이 각각 1, 0이 되도록 스케일링
        - StandardScaler() : scaler() 함수와 동일한 동작
- 표준화 : (요소값(하나의 데이터) - 평균) / 표준편차
- 삼성전자 vs 작은회사 주식 시세
- 몸무게 vs 키
    - 표준화 결과 : 몸무게 음수, 키 양수
    - 해석 : 몸무게는 평균 이하, 키는 평균 이상(=>마른몸)"""
    
# 전처리 기능을 제공하는 scikitlearn 라이브러리 및 모듈 가져오기 

from sklearn.preprocessing import scale, minmax_scale

# -3이상 5이하의 정수를 값으로 가지는 9행 1열 배열 생성 
x = (np.arange(9)-3).reshape(-1,1) #-1 주고, 1주면 열을 1로 고정하고, 행은 알아서 계산 
x                                  # np.arange(9)-3은 array전체에 -3을 일괄적으로 

scale(x)

df = pd.DataFrame(np.hstack([x,scale(x),minmax_scale(x)]))
df

# 전체 데이터에 대한 평균, 표준편차 (std : Standard deviation) 비교
# x에 대한 평균, 표준편차 
# scale(x)에 대한 평균, 표준편차
# minmax_scale(x)에 대한 평균, 표준편차

print('original : ',np.mean(df[0]), np.std(df[0]))
print('scale(x) : ',np.mean(df[1]), np.std(df[1]))
print('minmax_scale(x) : ',np.mean(df[2]), np.std(df[2]))

"""
### 정규화(Normalizaion)

- 정규화는 서로 다른 단위의 다차원 독립 변수에 대해 각 변수들의 상대적 크기 비교
- 정규화 결과값은 0 ~ 1 사이의 값을 가짐
- 단위가 서로 다른 경우
- 0이 아주 많은 경우
- sklearn 라이브러리에서 제공하는 클래스
    - normalize()"""
    
# 표준화 
# 정규화 : 표준화된 여러개의 자료를 비교?
# 사막 강우량을 젠다고 했을때, 365일중에 2일 정도 올텐데, 평균을 내봤자 의미가 없다. 

from sklearn.preprocessing import normalize

# 첫 번째 열 : -20 ~ -16 정수
# 두번째 열 : -2 ~ 2 정수
# 5행 2열의 2차원 배열 생성
x = np.vstack([(np.arange(5)-20),(np.arange(5)-2)]).T
x

# 표준화 (스케일링) 적용
y1 = scale(x)
y1

# 정규화 적용
y2 = normalize(x)
y2

# 정규화 여부 확인
# np.linalg.norm(data,axis=1) : 값 (np.array, 벡터)의 단위 

print(x)
print('x norm',np.linalg.norm(x,axis=1))

print(y1)
print('scale norm', np.linalg.norm(y1,axis=1))

print(y2)
print('normalize norm', np.linalg.norm(y2,axis=1))

# scale 했을때는 원래 숫자가 짐작이 가지 않았지만, normalize하면 원래 숫자에 대한 짐작이 가능하다?
