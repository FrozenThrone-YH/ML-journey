#목차

#
#
#
#
#
#
#
#
#
#
#
#

------------------------------------------------------------------------
기본셋팅
setwd("c:\\r_data")
install.packages("dplyr")
install.packages("foreign")
install.packages("ggplot2")
install.packages("readxl")
install.packages("KoNLP")
install.packages("wordcloud")
install.packages("stringr")
install.packages("tm")
install.packages("plotrix")
library(dplyr)
library(foreign)
library(ggplot2)
library(readxl)
library(KoNLP)
library(wordcloud)
library(RColorBrewer)
library(stringr)
library(tm)
library(plotrix)
Sys.setenv(JAVA_HOME='C:\\Program Files\\Java\\jre1.8.0_231')

------------------------------------------------------------------------
1교시

<실전분석>

#워드클라우드 
 1) 데이터에서 단어만 추출
 2) 단어 집합 생성
 3) 단어 필터링
 4) 단어 핸들링
 5) txt파일로 저장하고 table로 읽어서 공백제거 
    (불필요한 공백제거)
 6) 단어 빈도수 저장
 7) 워드클라우드 출력 
 8) 자바로딩 안될때(R 자바가 안잡혀서 에러가 뜨는 경우) 
     : Sys.setenv(JAVA_HOME='C:\\Program Files\\Java\\jre1.8.0_231')
 9) 

useSejongDic() ※시간이 좀 길다.스킵메세지가 뜨면 '1' 'all'로 한다. 
                 에러가 뜨면 '3' 'Rcpp'에서 자꾸 에러가 난다?

install.packages('Rcpp')
library(Rcpp)            ※이렇게 해도 안붙는다?

useSejongDic()
useNIADic()    ※일단 진행 

data1=readLines("BTS유엔연설_국문.txt")
data1

데이터가 깨질시 UTF-8로 저장 그래도 깨질시 ANSI로 설정해서 다른이름으로 저장(파일 이름 바꾸기)

data2=sapply(data1,extractNoun,USE.NAMES=F)
data2
head(unlist(data2),30)
data3=unlist(data2)
data3

data3에서 데이터 가공이 필요하다. 
ex) 저 = 나를 낮춘것, 나와 저를 합쳐야한다. 
    '한'이라는 단어가 애매하다. 
    '장' '살' '내' "" 이런것들 지운다. 

#gsub("변경전 글자","변경 후 글자","원본데이터")
data4=gsub("\\d+","",data3) ※숫자는 공백처리하겠다.
data4=gsub("한","",data3) ※"한"이라는 글자를 공백처리 
data4=gsub("저","나",data3)

data4=gsub("\\d+","",data3)
data4=gsub("한","",data4)
data4=gsub("저","나",data4)
data4=gsub("것","",data4)
data4=gsub(" ","",data4)
data4=gsub("-","",data4)
data4

write(unlist(data4),"BTS_국문연설.txt")
data5=read.table("BTS_국문연설.txt")
data5 ※공백이 다 사라졌다. 

nrow(data5) ※갯수가 몇개인가?
[1] 357 

wc=table(data5)
wc
head(sort(wc,decreasing=T),20)

data5
    나 여러분   우리   자신     들   사랑   이름 이야기     내 목소리 
    34     12     11     10      7      7      6      6      5      5 
  방탄 소년단   사람   시작   오늘   LOVE     그   무엇   시선   실수 
     5      5      4      4      4      3      3      3      3      3 

data4=gsub("들","",data4)
data4=gsub("그","",data4)

계속 삭제해준다. ※함수로 필요없는 단어들을 삭제하게 만들어서 실행시킬 수 도 잇다. 

write(unlist(data4),"BTS_국문연설_2.txt")
data5=read.table("BTS_국문연설_2.txt")
wc=table(data5)
head(sort(wc,decreasing=T),20)

library(RColorBrewer)

palete=brewer.pal(9,"Set3") S가 대문자 
wordcloud(names(wc),freq=wc,scale=c(5,1),rot.per=0.25,min.freq=1,random.color=T,random.order=F,colors=palete)
freq = 빈도수 / rot.per 회전 

gsub는 너무 노가다이다. 
필요없는 단어를 모아서 파일을 하나 만들어놔서 
반복적으로 비교해서 바꾸는 코드 작업을 할 수 있다. 

data1_1=readLines("remake.txt") ※Q_A에 답변 올려놓은걸 모아왔다. 
data1_1

data2_1=sapply(data1_1,extractNoun,USE.NAMES=F)
data2_1

data3_1=unlist(data2_1)
data3_1

data3_1=Filter(function(x){
                nchar(x)<=10},data3_1)
head(unlist(data3),30)

data4_1=gsub("\\d+","",data3_1)
data4_1=gsub("쌍","쌍꺼풀",data4_1)
data4_1=gsub("쌍커풀","쌍꺼풀",data4_1)
data4_1=gsub("메부리코","매부리코",data4_1)
data4_1=gsub(" ","",data4_1)
data4_1=gsub("\\'","",data4_1)
data4_1=gsub('\\"',"",data4_1)
data4_1=gsub('\\."',"",data4_1)
data4_1=gsub('수',"",data4_1)

이렇게 하면 시간이 너무 오래걸린다. 

write(unlist(data4_1),"remake_2.txt")
data5_1=read.table("remake_2.txt")
data5_1
nrow(data5_1)
wc1_1=table(data5_1)
wc1_1
head(sort(wc1_1,decreasing=T),20)

성형gsub이라는 파일에 필요없는 단어 모아둔 파일을 만든다.

txt=readLines("성형gsub.txt")
txt

cnt_txt=length(txt)
cnt_txt
i=1
for (i in 1:cnt_txt){
  data4_1=gsub((txt[i]),"",data4_1)
}
data4_1

data4_1=Filter(function(x){nchar(x)>=2},data4_1)
data4_1
write(unlist(data4_1),"remake_2_2.txt")
data5_1=read.table("remake_2_2.txt")
data5_1
nrow(data5_1)
wc=table(data5_1)
wc
head(sort(wc,decreasing=T),30)

wordcloud(names(wc),freq=wc,scale=c(5,1),rot.per=0.3,min.freq=2,random.ordor=F,)
※random.ordor = F -생성될때마다 바뀌지 말아라 

legend(0.3,0.9,"여고생들이 선호하는 성형부위",cex=0.8,fill=NA,border=NA,
       bg='white',text.col="red",text.font=2,box.col="blue")

일일이 데이터를 훑어 봐야 한다. 

remake2 라는 파일은 부작용에 관한 파일이다. 
------------------------------------------------------------------------
2교시

<부작용으로 각자 실습>

data101=readLines("remake2.txt")
data101
data201=sapply(data101,extractNoun,USE.NAMES=F)
data201
data301=unlist(data201)
data301
data301=Filter(function(x){nchar(x)>=2},data301)
data301
data301=gsub("\\d+","",data301)
data301=gsub("\\.","",data301)
head(unlist(data301),30)


txt101=readLines("sideeffect_gsub.txt")
txt101
cnt_txt101=length(txt101)
cnt_txt101
i=1
for (i in 1:cnt_txt101){
  data301=gsub((txt101[i]),"",data301)
}
data301
write(unlist(data301),"remake_side_effect.txt")
data501=read.table("remake_side_effect.txt")
data501
nrow(data501)
wc101=table(data501)
wc101
head(sort(wc101,decreasing=T),30)
palete101=brewer.pal(10,"Set3")
wordcloud(names(wc101),freq=wc101,scale=c(5,1),rot.per=0.3,min.freq=4,random.ordor=F,random.color=T,colors=palete)
legend(0.3,0.9,"성형수술 부잗용",cex=0.8,fill=NA,border=NA,
       bg='white',text.col="red",text.font=2,box.col="blue")

※부정적 단어를 보려면 삭제하는 단어가 적고
  부작용 부위를 보려면 손해배상, 법률, 변호사 같은 단어를 없앤다. 관점에 따라 지우는 단어가 다르다. 



<stringr 패키지 깔고, 활용>
<제주도 여행지 추천>
txt=readLines("jeju.txt")
place=sapply(txt,extractNoun,USE.NAMES=F)
place
head(unlist(place),30)
cdata=unlist(place)
cdata
place=str_replace_all(cdata,"[^[:alpha:]]","") #정규식활용-한글/영어 외에는 다 지워라
place=gsub(" ","",place)
txt=readLines("제주도여행코스gsub.txt")
txt
cnt_txt=length(txt)
cnt_txt
i=1
for(i in 1:cnt_txt){
  place=gsub((txt[i]),"",place)
}
place
place=Filter(function(x){nchar(x)>=2},place)
write(unlist(place),"jeju_2.txt")
rev=read.table("jeju_2.txt") #필요없는 공백 삭제
rev
nrow(rev)
wc=table(rev)
wc
head(sort(wc,decreasing=T),30)
palete=brewer.pal(9,"Set3")
wordcloud(names(wc),freq=wc,scale=c(5,1),rot.per=0.3,random.order = F,random.color = T,min.freq=2,colors=palete)

※실제로 성산일출봉과 천지연 폭포인데 "제주도여행지.txt"
  단어 분리가 되면 안되는 것을 따로 만들어서 jeju.txt 하기 전에
   mergeUserDic(data.frame(readLines("제주도여행지.txt"),"ncn")) 를 해준다.

<다시 실행>
★mergeUserDic(data.frame(readLines("제주도여행지.txt"),"ncn"))
txt=readLines("jeju.txt")
place=sapply(txt,extractNoun,USE.NAMES=F)
place
head(unlist(place),30)
cdata=unlist(place)
cdata
place=str_replace_all(cdata,"[^[:alpha:]]","") #정규식활용-한글/영어 외에는 다 지워라
place=gsub(" ","",place)
txt=readLines("제주도여행코스gsub.txt")
txt
cnt_txt=length(txt)
cnt_txt
i=1
for(i in 1:cnt_txt){
  place=gsub((txt[i]),"",place)
}
place
place=Filter(function(x){nchar(x)>=2},place)
write(unlist(place),"jeju_2.txt")
rev=read.table("jeju_2.txt") #필요없는 공백 삭제
rev

nrow(rev)
wc=table(rev)
wc
head(sort(wc,decreasing=T),30)
palete=brewer.pal(9,"Set3")
wordcloud(names(wc),freq=wc,scale=c(5,1),rot.per=0.3,random.order = F,random.color = T,min.freq=2,colors=palete)

<영문>
<tm package 활용>

영어는 말 뭉치를 만드는 작업이 중요하다. 

data1=readLines("BTS유엔연설_영문_.txt") ※깨지면 ANSI로 다른이름저장
data1

data1=readLines("BTS유엔연설_영문_.txt")
data1

corp1=VCorpus(VectorSource(data1))
corp1

<<VCorpus>>
Metadata:  corpus specific: 0, document level (indexed): 0
Content:  documents: 31 (text라인이 31개라는 의미)

inspect(corp1)

[[31]]
<<PlainTextDocument>>
Metadata:  7
Content:  chars: 21    이런식으로 형성  - 공백포함해서 글자수의 전체 

corp2=tm_map(corp1,stripWhitespace)#여러개 공백을 하나로 만들어라
corp2=tm_map(corp1,tolower)#대문자를 소문자로 바꿔라 
corp2=tm_map(corp1,removeNumbers) #숫자제거
corp2=tm_map(corp1,removePunctuation) #마침표, 콤마, 세미콜론, 콜론 등의 문자 제거 
corp2=tm_map(corp1,PlainTextDocument) #일반문서전환 
sword2=c(stopwords('en'),"and","but","not","what","when") #불용어 제거 
corp2=tm_map(corp2,removeWords,sword2) #불용어 제거를 위한 변수를 여기서 사용 

tdm2=TermDocumentMatrix(corp2)
tdm2

<<TermDocumentMatrix (terms: 244, documents: 31)>>
Non-/sparse entries: 321/7243
Sparsity           : 96%  #단어추출이 된게 96%
Maximal term length: 14
Weighting          : term frequency (tf)

tdm2=TermDocumentMatrix(corp2,control=list(wordLengths=c(1,Inf))) 
tdm2

<<TermDocumentMatrix (terms: 251, documents: 31)>>
Non-/sparse entries: 336/7445
Sparsity           : 96%
Maximal term length: 14
Weighting          : term frequency (tf)

#영문을 할때 위에 작업은 반드시 필요하다.

findFreqTerms(tdm2,10) 상관분석을 하려고 했는데 일단 필요없음?

corp4=as.matrix(tdm2) #보기 어려움
corp4   
fre1=sort(rowSums(corp4),decreasing = T)
fre2=sort(colSums(corp4),decreasing = T)
head(fre2,20)
character(0) character(0) character(0) character(0) character(0) 
          42           37           37           37           35 
character(0) character(0) character(0) character(0) character(0) 
          31           30           26           17           13 
character(0) character(0) character(0) character(0) character(0) 
           8            8            7            7            6 
character(0) character(0) character(0) character(0) character(0) 
           6            5            4            4            3 

dim(corp4)
colnames(corp4)=c(1:31)
fre=sort(colSums(corp4),decreasing=T)
> fre
10  3  6 14 28 21 17 19  1 27 25 26  8 16  9 11 24  5 23 13 30 31  2  4  7 
42 37 37 37 35 31 30 26 17 13  8  8  7  7  6  6  5  4  4  3  2  2  0  0  0 
12 15 18 20 22 29 
 0  0  0  0  0  0 

palete=brewer.pal(7,"Set3")
wordcloud(names(fre1),freq=fre1,scale=c(5,1),min.freq=2,colors=palete,random.order = F,random.color=T)

한글과 영문의 빈도수가 다르다. 

barplot(fre1,las=2,glim=c(0,5)) 빈도수를 bar plot으로 만들수 있다. 



------------------------------------------------------------------------
3교시

<다른 차트 활용하기 - 제주도 재활용>
mergeUserDic(data.frame(readLines("제주도여행지.txt"),"ncn"))
txt=readLines("jeju.txt")
place=sapply(txt,extractNoun,USE.NAMES=F)
place
head(unlist(place),30)
cdata=unlist(place)
cdata
place=str_replace_all(cdata,"[^[:alpha:]]","") #정규식활용-한글/영어 외에는 다 지워라
place=gsub(" ","",place)
txt=readLines("제주도여행코스gsub.txt")
txt
cnt_txt=length(txt)
cnt_txt
i=1
for(i in 1:cnt_txt){
  place=gsub((txt[i]),"",place)
}
place
place=Filter(function(x){nchar(x)>=2},place)
write(unlist(place),"jeju_2.txt")
rev=read.table("jeju_2.txt") #필요없는 공백 삭제
rev

nrow(rev)
wc=table(rev)
wc
head(sort(wc,decreasing=T),30)


palete=brewer.pal(9,"Set3")
wordcloud(names(wc),freq=wc,scale=c(5,1),rot.per=0.1,random.order = F,random.color = T,min.freq=6,colors=palete)

#파이로 찍어보기 
top10=head(sort(wc,decreasing=T),10)
top10
pct=round(top10/sum(top10)*100,1)
names(top10)
lab=paste(names(top10),"\n",pct,"%")
pie(top10,col=rainbow(10),radius=1,main="제주도 추천명소 top10",cex=0.8,labels=lab)

#바차트로 찍어보기
bchart=head(sort(wc,decreasing=T),10)
bchart
bp=barplot(bchart,main="제주도 추천명소 Top10",col=rainbow(10),cex.names=0.7,las=2,ylim=c(0,25))

pct=round(bchart/sum(bchart)*100,1)
pct
text(x=bp,y=bchart*1.05,labels=paste("(",pct,"%",")"),col="black",cex=0.7)
text(x=bp,y=bchart*0.95,labels=paste(bchart,"건"),col="black",cex=0.7)

#바차트를 눕히려면

bp=barplot(bchart,main="제주도 추천명소 Top10",col=rainbow(10),cex.names=0.7,las=1,xlim=c(0,25),horiz=T)

pct=round(bchart/sum(bchart)*100,1)
pct
text(y=bp,x=bchart*1.15,labels=paste("(",pct,"%",")"),col="black",cex=0.7)

text(y=bp,x=bchart*0.95,labels=paste(bchart,"건"),col="black",cex=0.7)

#바차트를 3D로 만드려면?

th_pct=round(bchart/sum(bchart)*100,1)
th_names=names(bchart)
th_labels=paste(th_names,"\n","(",th_pct,")")
pie3D(bchart, main="제주도 추천 Top10",col=rainbow(10),cex=0.3,labels=th_labels,explode=0.05)

------------------------------------------------------------------------
4교
